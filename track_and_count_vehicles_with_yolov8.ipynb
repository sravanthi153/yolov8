{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca56184a9cb446dcb4b07d47fe893b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f45831bf430d4ee292454eb928a0f3ac",
              "IPY_MODEL_3ac4d3713a754523b8de178d20fb6203",
              "IPY_MODEL_563b5926d6e24c2cafbbde7f21d151fa"
            ],
            "layout": "IPY_MODEL_1f3b1ae99d644ede96d75e971f519cd2"
          }
        },
        "f45831bf430d4ee292454eb928a0f3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e494d011c75c4d29ac31a4b13f06d804",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dbf6b3970e5f401682eeffd0438e2ffd",
            "value": "100%"
          }
        },
        "3ac4d3713a754523b8de178d20fb6203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c9f62f970340df8d628dc8731b7202",
            "max": 136867539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebca31fa0c4e4eb8b4486967b8b7c3e3",
            "value": 136867539
          }
        },
        "563b5926d6e24c2cafbbde7f21d151fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c419e1c97fc47b18331c318c721c3ed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_19d00256a0244963ace0ea4530177f71",
            "value": " 131M/131M [00:00&lt;00:00, 176MB/s]"
          }
        },
        "1f3b1ae99d644ede96d75e971f519cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e494d011c75c4d29ac31a4b13f06d804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf6b3970e5f401682eeffd0438e2ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c9f62f970340df8d628dc8731b7202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebca31fa0c4e4eb8b4486967b8b7c3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c419e1c97fc47b18331c318c721c3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d00256a0244963ace0ea4530177f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12927ed4ce494cd6a424d0b1e794049b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8116e8dca64b4d45b3d107bed62694f2",
              "IPY_MODEL_46f61fa928124753bc0b0b636e499423",
              "IPY_MODEL_aff717d0dc9f4508806c91ea1978831a"
            ],
            "layout": "IPY_MODEL_1da57bd414654cbdb96d302d24180450"
          }
        },
        "8116e8dca64b4d45b3d107bed62694f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c853f2bb57497985f0fc7cbee56808",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ad474f078d44740899e699b4b4ea298",
            "value": "100%"
          }
        },
        "46f61fa928124753bc0b0b636e499423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6f2ead71f045f7a28b7318ff1d0d60",
            "max": 538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11c32a6c641248458fae5434f5e9201a",
            "value": 538
          }
        },
        "aff717d0dc9f4508806c91ea1978831a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1ebc5fefb804e3ebb893a0d91c3b759",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4c44708796ad495d82046b9b41b61485",
            "value": " 538/538 [01:29&lt;00:00,  7.33it/s]"
          }
        },
        "1da57bd414654cbdb96d302d24180450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c853f2bb57497985f0fc7cbee56808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad474f078d44740899e699b4b4ea298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6f2ead71f045f7a28b7318ff1d0d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c32a6c641248458fae5434f5e9201a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1ebc5fefb804e3ebb893a0d91c3b759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c44708796ad495d82046b9b41b61485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalvaakhil/yolov8_deepsort_algo/blob/main/track_and_count_vehicles_with_yolov8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4okzdHlKMaj",
        "outputId": "3673fb87-b976-48d3-b87b-31afbd8dcdb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 24 11:42:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "984J4pv4K2D-",
        "outputId": "f4f60323-852b-4da1-b130-4a64d0f93091"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download video"
      ],
      "metadata": {
        "id": "J_Zyej4SSZNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctvdpAiRSb1_",
        "outputId": "8aef782b-8059-4234-8cd5-76eaf5b5aa98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-02-24 11:42:29--  https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.119.101, 108.177.119.138, 108.177.119.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.119.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-ag-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/sphg9ld6lrm70arfd61iamlnsi5qgl97/1677238950000/04309230031174164349/*/1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-?e=download&uuid=6c748d36-4c8e-4963-9718-8d0ff31d7c2f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-02-24 11:42:30--  https://doc-0s-ag-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/sphg9ld6lrm70arfd61iamlnsi5qgl97/1677238950000/04309230031174164349/*/1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-?e=download&uuid=6c748d36-4c8e-4963-9718-8d0ff31d7c2f\n",
            "Resolving doc-0s-ag-docs.googleusercontent.com (doc-0s-ag-docs.googleusercontent.com)... 173.194.79.132, 2a00:1450:4013:c05::84\n",
            "Connecting to doc-0s-ag-docs.googleusercontent.com (doc-0s-ag-docs.googleusercontent.com)|173.194.79.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35345757 (34M) [video/mp4]\n",
            "Saving to: â€˜vehicle-counting.mp4â€™\n",
            "\n",
            "vehicle-counting.mp 100%[===================>]  33.71M   188MB/s    in 0.2s    \n",
            "\n",
            "2023-02-24 11:42:30 (188 MB/s) - â€˜vehicle-counting.mp4â€™ saved [35345757/35345757]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"{HOME}/vehicle-counting.mp4\""
      ],
      "metadata": {
        "id": "gtxQLn33TBWo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "IGckxTNGLKDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f82127-df40-44d6-8417-fff0ace344e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.44 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 24.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "!cd ByteTrack && pip3 install -q -r requirements.txt\n",
        "!cd ByteTrack && python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KdBkOflo2xY",
        "outputId": "aa9ad1d0-5e4e-4b7b-a286-2d0485248553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "rwg-lY49o7Sf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Roboflow Supervision"
      ],
      "metadata": {
        "id": "_kSHFj8uQ9qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60yX_PFQ9A2",
        "outputId": "238009c6-602b-43f4-9cef-e20d1b55323e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ],
      "metadata": {
        "id": "7YDohOpMTWH5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections, \n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "    \n",
        "    tracker_ids = [None] * len(detections)\n",
        "    \n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "SE0G6LvFAXlk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load trained YOLOv8 model"
      ],
      "metadata": {
        "id": "c_417m4g9XVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "MODEL = \"yolov8x.pt\""
      ],
      "metadata": {
        "id": "m3FMq5FcUsRc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ca56184a9cb446dcb4b07d47fe893b2b",
            "f45831bf430d4ee292454eb928a0f3ac",
            "3ac4d3713a754523b8de178d20fb6203",
            "563b5926d6e24c2cafbbde7f21d151fa",
            "1f3b1ae99d644ede96d75e971f519cd2",
            "e494d011c75c4d29ac31a4b13f06d804",
            "dbf6b3970e5f401682eeffd0438e2ffd",
            "16c9f62f970340df8d628dc8731b7202",
            "ebca31fa0c4e4eb8b4486967b8b7c3e3",
            "0c419e1c97fc47b18331c318c721c3ed",
            "19d00256a0244963ace0ea4530177f71"
          ]
        },
        "id": "KFCV_2TR9eo_",
        "outputId": "2568c589-1a7c-4425-a7ab-0e2390d5e6f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to yolov8x.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/131M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca56184a9cb446dcb4b07d47fe893b2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and annotate single frame"
      ],
      "metadata": {
        "id": "6to6MgPmTnCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES_DICT = model.model.names\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "yKuDnOIxsN6l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame)\n",
        "detections = Detections(\n",
        "    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        ")\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "    for _, confidence, class_id, tracker_id\n",
        "    in detections\n",
        "]\n",
        "# annotate and display frame\n",
        "frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "show_frame_in_notebook(frame, (16, 16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZQsgCa0cFvH",
        "outputId": "242c07a7-1d26-4291-f1c1-e284dab1d38b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.44 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 62.0ms\n",
            "Speed: 0.5ms preprocess, 62.0ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict and annotate whole video "
      ],
      "metadata": {
        "id": "3ZbGmYfiT0EV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "LINE_START = Point(50, 1500)\n",
        "LINE_END = Point(3840-50, 1500)\n",
        "\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/vehicle-counting-result.mp4\""
      ],
      "metadata": {
        "id": "MjP8Pn10XuJm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btq7JavXknU",
        "outputId": "11656861-9317-479c-c647-b95fe8dc35c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VideoInfo(width=3840, height=2160, fps=25, total_frames=538)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "12927ed4ce494cd6a424d0b1e794049b",
            "8116e8dca64b4d45b3d107bed62694f2",
            "46f61fa928124753bc0b0b636e499423",
            "aff717d0dc9f4508806c91ea1978831a",
            "1da57bd414654cbdb96d302d24180450",
            "14c853f2bb57497985f0fc7cbee56808",
            "1ad474f078d44740899e699b4b4ea298",
            "1b6f2ead71f045f7a28b7318ff1d0d60",
            "11c32a6c641248458fae5434f5e9201a",
            "c1ebc5fefb804e3ebb893a0d91c3b759",
            "4c44708796ad495d82046b9b41b61485"
          ]
        },
        "id": "Q9ppb7bFvWfc",
        "outputId": "c06746e8-de3d-4e6f-f3b2-7cafd9057051"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12927ed4ce494cd6a424d0b1e794049b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.4ms\n",
            "Speed: 0.7ms preprocess, 64.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.3ms\n",
            "Speed: 0.6ms preprocess, 62.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 58.9ms\n",
            "Speed: 0.7ms preprocess, 58.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.9ms\n",
            "Speed: 0.6ms preprocess, 57.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 57.9ms\n",
            "Speed: 0.6ms preprocess, 57.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 58.0ms\n",
            "Speed: 0.6ms preprocess, 58.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.9ms\n",
            "Speed: 0.6ms preprocess, 57.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 59.6ms\n",
            "Speed: 0.6ms preprocess, 59.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.8ms\n",
            "Speed: 0.6ms preprocess, 54.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.9ms\n",
            "Speed: 0.6ms preprocess, 53.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.7ms\n",
            "Speed: 0.6ms preprocess, 53.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.7ms\n",
            "Speed: 0.6ms preprocess, 53.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.0ms\n",
            "Speed: 0.6ms preprocess, 53.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.7ms\n",
            "Speed: 0.7ms preprocess, 52.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.9ms\n",
            "Speed: 0.5ms preprocess, 51.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 52.0ms\n",
            "Speed: 0.6ms preprocess, 52.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 52.2ms\n",
            "Speed: 0.6ms preprocess, 52.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.2ms\n",
            "Speed: 0.6ms preprocess, 52.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 48.8ms\n",
            "Speed: 0.5ms preprocess, 48.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.7ms\n",
            "Speed: 0.6ms preprocess, 48.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.7ms\n",
            "Speed: 0.6ms preprocess, 48.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 46.3ms\n",
            "Speed: 0.7ms preprocess, 46.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 46.2ms\n",
            "Speed: 0.6ms preprocess, 46.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 46.0ms\n",
            "Speed: 0.6ms preprocess, 46.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 48.1ms\n",
            "Speed: 0.6ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 40.9ms\n",
            "Speed: 0.6ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 1 traffic light, 40.5ms\n",
            "Speed: 2.9ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.8ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.1ms\n",
            "Speed: 0.6ms preprocess, 41.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 43.3ms\n",
            "Speed: 0.7ms preprocess, 43.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 45.6ms\n",
            "Speed: 0.6ms preprocess, 45.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 trucks, 46.7ms\n",
            "Speed: 0.6ms preprocess, 46.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 52.6ms\n",
            "Speed: 0.5ms preprocess, 52.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 54.7ms\n",
            "Speed: 0.6ms preprocess, 54.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 55.8ms\n",
            "Speed: 0.6ms preprocess, 55.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 55.9ms\n",
            "Speed: 0.6ms preprocess, 55.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 53.7ms\n",
            "Speed: 0.5ms preprocess, 53.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 54.6ms\n",
            "Speed: 0.5ms preprocess, 54.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 58.4ms\n",
            "Speed: 0.5ms preprocess, 58.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 60.8ms\n",
            "Speed: 0.6ms preprocess, 60.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 62.8ms\n",
            "Speed: 0.6ms preprocess, 62.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 65.9ms\n",
            "Speed: 0.6ms preprocess, 65.9ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 65.8ms\n",
            "Speed: 0.6ms preprocess, 65.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 64.6ms\n",
            "Speed: 2.2ms preprocess, 64.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 65.2ms\n",
            "Speed: 2.1ms preprocess, 65.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 68.7ms\n",
            "Speed: 0.7ms preprocess, 68.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 61.5ms\n",
            "Speed: 0.6ms preprocess, 61.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 61.4ms\n",
            "Speed: 0.6ms preprocess, 61.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 61.8ms\n",
            "Speed: 0.5ms preprocess, 61.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 60.3ms\n",
            "Speed: 0.6ms preprocess, 60.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 59.1ms\n",
            "Speed: 0.6ms preprocess, 59.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 53.9ms\n",
            "Speed: 0.7ms preprocess, 53.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 53.9ms\n",
            "Speed: 0.5ms preprocess, 53.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 52.7ms\n",
            "Speed: 0.6ms preprocess, 52.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 3 trucks, 45.5ms\n",
            "Speed: 0.5ms preprocess, 45.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 45.4ms\n",
            "Speed: 0.5ms preprocess, 45.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 45.4ms\n",
            "Speed: 1.8ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 1 bench, 40.7ms\n",
            "Speed: 0.7ms preprocess, 40.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 1 bench, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 refrigerator, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.5ms\n",
            "Speed: 0.5ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.7ms\n",
            "Speed: 0.7ms preprocess, 40.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.8ms\n",
            "Speed: 0.6ms preprocess, 41.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 refrigerator, 43.6ms\n",
            "Speed: 0.6ms preprocess, 43.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.8ms\n",
            "Speed: 0.6ms preprocess, 45.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.5ms\n",
            "Speed: 0.9ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.5ms preprocess, 45.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.0ms\n",
            "Speed: 3.3ms preprocess, 46.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.8ms\n",
            "Speed: 0.6ms preprocess, 47.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.7ms\n",
            "Speed: 0.6ms preprocess, 49.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.9ms\n",
            "Speed: 0.6ms preprocess, 49.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.4ms\n",
            "Speed: 0.6ms preprocess, 50.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.0ms\n",
            "Speed: 0.6ms preprocess, 49.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.4ms\n",
            "Speed: 0.6ms preprocess, 50.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.9ms\n",
            "Speed: 0.6ms preprocess, 48.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.6ms\n",
            "Speed: 0.5ms preprocess, 51.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.2ms\n",
            "Speed: 0.5ms preprocess, 44.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.2ms\n",
            "Speed: 0.7ms preprocess, 44.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 0.6ms preprocess, 44.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.7ms\n",
            "Speed: 0.6ms preprocess, 43.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.7ms\n",
            "Speed: 0.5ms preprocess, 43.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.6ms\n",
            "Speed: 0.6ms preprocess, 43.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.5ms\n",
            "Speed: 0.6ms preprocess, 43.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.5ms\n",
            "Speed: 0.6ms preprocess, 43.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.6ms\n",
            "Speed: 0.6ms preprocess, 43.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.7ms\n",
            "Speed: 0.6ms preprocess, 43.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.6ms\n",
            "Speed: 0.6ms preprocess, 43.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.6ms\n",
            "Speed: 0.6ms preprocess, 43.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.5ms\n",
            "Speed: 0.5ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.6ms\n",
            "Speed: 0.6ms preprocess, 51.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.8ms\n",
            "Speed: 0.5ms preprocess, 47.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.2ms\n",
            "Speed: 0.8ms preprocess, 55.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.7ms\n",
            "Speed: 0.6ms preprocess, 52.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.1ms\n",
            "Speed: 0.6ms preprocess, 52.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.7ms\n",
            "Speed: 0.5ms preprocess, 54.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.8ms\n",
            "Speed: 0.6ms preprocess, 57.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.7ms\n",
            "Speed: 0.5ms preprocess, 57.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 59.3ms\n",
            "Speed: 0.5ms preprocess, 59.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 61.5ms\n",
            "Speed: 0.6ms preprocess, 61.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.4ms\n",
            "Speed: 0.6ms preprocess, 62.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.6ms\n",
            "Speed: 0.6ms preprocess, 62.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.2ms\n",
            "Speed: 0.5ms preprocess, 64.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.3ms\n",
            "Speed: 0.6ms preprocess, 68.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.8ms\n",
            "Speed: 0.6ms preprocess, 55.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.7ms\n",
            "Speed: 0.5ms preprocess, 55.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.7ms\n",
            "Speed: 0.6ms preprocess, 55.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.5ms\n",
            "Speed: 0.6ms preprocess, 55.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.4ms\n",
            "Speed: 0.6ms preprocess, 47.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.4ms\n",
            "Speed: 0.6ms preprocess, 47.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.4ms\n",
            "Speed: 0.7ms preprocess, 47.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.5ms\n",
            "Speed: 0.6ms preprocess, 41.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 41.3ms\n",
            "Speed: 0.6ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.2ms\n",
            "Speed: 0.6ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.1ms\n",
            "Speed: 0.6ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 41.1ms\n",
            "Speed: 3.7ms preprocess, 41.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 41.1ms\n",
            "Speed: 0.9ms preprocess, 41.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.0ms\n",
            "Speed: 0.6ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.6ms\n",
            "Speed: 0.9ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.5ms\n",
            "Speed: 1.0ms preprocess, 40.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.7ms\n",
            "Speed: 0.5ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.6ms\n",
            "Speed: 0.9ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.3ms\n",
            "Speed: 0.6ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.9ms\n",
            "Speed: 0.5ms preprocess, 45.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.2ms\n",
            "Speed: 0.6ms preprocess, 43.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.0ms\n",
            "Speed: 0.6ms preprocess, 44.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.2ms\n",
            "Speed: 0.5ms preprocess, 44.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.1ms\n",
            "Speed: 0.6ms preprocess, 43.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.0ms\n",
            "Speed: 0.5ms preprocess, 43.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.1ms\n",
            "Speed: 0.6ms preprocess, 43.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.2ms\n",
            "Speed: 0.6ms preprocess, 43.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.0ms\n",
            "Speed: 0.6ms preprocess, 43.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.6ms\n",
            "Speed: 0.6ms preprocess, 42.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.3ms\n",
            "Speed: 0.5ms preprocess, 51.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.2ms\n",
            "Speed: 0.5ms preprocess, 53.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.4ms\n",
            "Speed: 0.6ms preprocess, 48.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 59.3ms\n",
            "Speed: 0.6ms preprocess, 59.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 59.0ms\n",
            "Speed: 0.6ms preprocess, 59.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.9ms\n",
            "Speed: 3.4ms preprocess, 57.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.1ms\n",
            "Speed: 0.6ms preprocess, 63.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 57.8ms\n",
            "Speed: 3.4ms preprocess, 57.8ms inference, 10.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.0ms\n",
            "Speed: 0.6ms preprocess, 63.0ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.8ms\n",
            "Speed: 0.7ms preprocess, 62.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 67.6ms\n",
            "Speed: 0.6ms preprocess, 67.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.0ms\n",
            "Speed: 0.6ms preprocess, 64.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 59.7ms\n",
            "Speed: 0.5ms preprocess, 59.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.1ms\n",
            "Speed: 0.6ms preprocess, 54.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.2ms\n",
            "Speed: 0.6ms preprocess, 55.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.1ms\n",
            "Speed: 0.6ms preprocess, 54.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.0ms\n",
            "Speed: 0.5ms preprocess, 54.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 51.6ms\n",
            "Speed: 0.6ms preprocess, 51.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.7ms\n",
            "Speed: 0.6ms preprocess, 50.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.4ms\n",
            "Speed: 0.5ms preprocess, 50.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.3ms\n",
            "Speed: 0.6ms preprocess, 50.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.4ms\n",
            "Speed: 0.6ms preprocess, 50.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 0.5ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.6ms\n",
            "Speed: 0.5ms preprocess, 45.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.5ms\n",
            "Speed: 0.6ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.6ms\n",
            "Speed: 0.6ms preprocess, 45.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.8ms\n",
            "Speed: 0.5ms preprocess, 45.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.5ms\n",
            "Speed: 0.5ms preprocess, 45.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 0.5ms preprocess, 45.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.5ms\n",
            "Speed: 0.6ms preprocess, 49.5ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.1ms\n",
            "Speed: 0.6ms preprocess, 51.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.5ms\n",
            "Speed: 0.6ms preprocess, 51.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 51.2ms\n",
            "Speed: 0.6ms preprocess, 51.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.4ms\n",
            "Speed: 0.5ms preprocess, 51.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.9ms\n",
            "Speed: 3.6ms preprocess, 52.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 54.1ms\n",
            "Speed: 0.5ms preprocess, 54.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 53.0ms\n",
            "Speed: 0.6ms preprocess, 53.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 48.5ms\n",
            "Speed: 0.5ms preprocess, 48.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 48.4ms\n",
            "Speed: 0.6ms preprocess, 48.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 48.0ms\n",
            "Speed: 0.5ms preprocess, 48.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.9ms\n",
            "Speed: 0.6ms preprocess, 47.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 46.7ms\n",
            "Speed: 0.5ms preprocess, 46.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 1 traffic light, 46.7ms\n",
            "Speed: 0.6ms preprocess, 46.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 3 trucks, 46.7ms\n",
            "Speed: 0.6ms preprocess, 46.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.8ms\n",
            "Speed: 0.5ms preprocess, 46.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 47.2ms\n",
            "Speed: 0.6ms preprocess, 47.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 46.9ms\n",
            "Speed: 0.6ms preprocess, 46.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 47.1ms\n",
            "Speed: 0.6ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 46.6ms\n",
            "Speed: 0.6ms preprocess, 46.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 51.2ms\n",
            "Speed: 0.6ms preprocess, 51.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 46.8ms\n",
            "Speed: 0.6ms preprocess, 46.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 46.9ms\n",
            "Speed: 0.5ms preprocess, 46.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 50.1ms\n",
            "Speed: 0.6ms preprocess, 50.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.1ms\n",
            "Speed: 0.6ms preprocess, 51.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 47.2ms\n",
            "Speed: 0.5ms preprocess, 47.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.7ms\n",
            "Speed: 0.6ms preprocess, 44.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.3ms\n",
            "Speed: 0.5ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.7ms\n",
            "Speed: 0.6ms preprocess, 44.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.5ms\n",
            "Speed: 0.6ms preprocess, 43.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.5ms\n",
            "Speed: 0.5ms preprocess, 43.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.5ms\n",
            "Speed: 0.5ms preprocess, 43.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.5ms\n",
            "Speed: 0.5ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.9ms\n",
            "Speed: 0.6ms preprocess, 43.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.5ms\n",
            "Speed: 0.6ms preprocess, 43.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.1ms\n",
            "Speed: 0.7ms preprocess, 41.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.4ms\n",
            "Speed: 0.6ms preprocess, 44.4ms inference, 8.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.3ms\n",
            "Speed: 0.6ms preprocess, 52.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.8ms\n",
            "Speed: 0.5ms preprocess, 55.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 41.7ms\n",
            "Speed: 0.7ms preprocess, 41.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 0.6ms preprocess, 41.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.3ms\n",
            "Speed: 0.6ms preprocess, 41.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 50.6ms\n",
            "Speed: 0.7ms preprocess, 50.6ms inference, 8.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.7ms\n",
            "Speed: 0.6ms preprocess, 52.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 54.6ms\n",
            "Speed: 0.6ms preprocess, 54.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 60.6ms\n",
            "Speed: 0.6ms preprocess, 60.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 59.9ms\n",
            "Speed: 0.6ms preprocess, 59.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 59.0ms\n",
            "Speed: 0.6ms preprocess, 59.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 58.9ms\n",
            "Speed: 0.6ms preprocess, 58.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 65.5ms\n",
            "Speed: 0.6ms preprocess, 65.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 61.7ms\n",
            "Speed: 0.6ms preprocess, 61.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 62.9ms\n",
            "Speed: 0.6ms preprocess, 62.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.2ms\n",
            "Speed: 0.6ms preprocess, 64.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 60.0ms\n",
            "Speed: 0.6ms preprocess, 60.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 55.2ms\n",
            "Speed: 0.5ms preprocess, 55.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 53.8ms\n",
            "Speed: 0.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 54.4ms\n",
            "Speed: 0.6ms preprocess, 54.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 53.9ms\n",
            "Speed: 0.5ms preprocess, 53.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 54.1ms\n",
            "Speed: 0.6ms preprocess, 54.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.1ms\n",
            "Speed: 0.6ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.1ms\n",
            "Speed: 0.6ms preprocess, 48.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.1ms\n",
            "Speed: 0.6ms preprocess, 48.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.1ms\n",
            "Speed: 0.6ms preprocess, 48.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 49.2ms\n",
            "Speed: 0.6ms preprocess, 49.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.0ms\n",
            "Speed: 0.6ms preprocess, 48.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.0ms\n",
            "Speed: 0.5ms preprocess, 48.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 50.6ms\n",
            "Speed: 0.6ms preprocess, 50.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 48.0ms\n",
            "Speed: 0.6ms preprocess, 48.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.2ms\n",
            "Speed: 0.6ms preprocess, 48.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.0ms\n",
            "Speed: 0.5ms preprocess, 48.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.2ms\n",
            "Speed: 0.5ms preprocess, 48.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.0ms\n",
            "Speed: 0.6ms preprocess, 51.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.0ms\n",
            "Speed: 2.1ms preprocess, 52.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.6ms\n",
            "Speed: 0.6ms preprocess, 52.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 53.2ms\n",
            "Speed: 0.6ms preprocess, 53.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.6ms\n",
            "Speed: 0.5ms preprocess, 45.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.2ms\n",
            "Speed: 4.2ms preprocess, 45.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.8ms preprocess, 44.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 44.8ms\n",
            "Speed: 0.5ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 44.9ms\n",
            "Speed: 0.6ms preprocess, 44.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.7ms\n",
            "Speed: 0.5ms preprocess, 44.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 49.6ms\n",
            "Speed: 0.5ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.1ms\n",
            "Speed: 0.6ms preprocess, 51.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.1ms\n",
            "Speed: 0.5ms preprocess, 51.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 44.3ms\n",
            "Speed: 0.7ms preprocess, 44.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 41.1ms\n",
            "Speed: 0.6ms preprocess, 41.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 42.9ms\n",
            "Speed: 0.6ms preprocess, 42.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 0.6ms preprocess, 40.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.7ms\n",
            "Speed: 0.6ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 92.4ms\n",
            "Speed: 0.6ms preprocess, 92.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.9ms\n",
            "Speed: 0.5ms preprocess, 52.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 57.9ms\n",
            "Speed: 0.9ms preprocess, 57.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.6ms\n",
            "Speed: 0.6ms preprocess, 55.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 84.9ms\n",
            "Speed: 0.6ms preprocess, 84.9ms inference, 12.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 62.7ms\n",
            "Speed: 0.6ms preprocess, 62.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 75.3ms\n",
            "Speed: 0.5ms preprocess, 75.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 88.7ms\n",
            "Speed: 10.6ms preprocess, 88.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.4ms\n",
            "Speed: 0.6ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.1ms\n",
            "Speed: 0.6ms preprocess, 64.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 67.4ms\n",
            "Speed: 0.6ms preprocess, 67.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.6ms\n",
            "Speed: 0.6ms preprocess, 64.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 68.9ms\n",
            "Speed: 0.6ms preprocess, 68.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 65.1ms\n",
            "Speed: 0.6ms preprocess, 65.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 68.9ms\n",
            "Speed: 0.6ms preprocess, 68.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 64.0ms\n",
            "Speed: 2.6ms preprocess, 64.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 74.6ms\n",
            "Speed: 0.6ms preprocess, 74.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 66.3ms\n",
            "Speed: 0.6ms preprocess, 66.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 69.0ms\n",
            "Speed: 0.5ms preprocess, 69.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 62.9ms\n",
            "Speed: 0.6ms preprocess, 62.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 60.5ms\n",
            "Speed: 0.6ms preprocess, 60.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.9ms\n",
            "Speed: 0.5ms preprocess, 53.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 54.6ms\n",
            "Speed: 0.6ms preprocess, 54.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.9ms\n",
            "Speed: 0.6ms preprocess, 53.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.4ms\n",
            "Speed: 0.6ms preprocess, 53.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.7ms\n",
            "Speed: 0.6ms preprocess, 45.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.6ms\n",
            "Speed: 0.6ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.4ms\n",
            "Speed: 0.6ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.3ms\n",
            "Speed: 0.6ms preprocess, 45.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 49.3ms\n",
            "Speed: 1.5ms preprocess, 49.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.9ms\n",
            "Speed: 0.7ms preprocess, 44.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.7ms\n",
            "Speed: 0.6ms preprocess, 43.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.5ms preprocess, 42.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.9ms\n",
            "Speed: 0.6ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 0.6ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 0.6ms preprocess, 41.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.6ms\n",
            "Speed: 0.6ms preprocess, 41.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 0.7ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.5ms\n",
            "Speed: 0.6ms preprocess, 42.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 0.5ms preprocess, 41.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.2ms\n",
            "Speed: 0.6ms preprocess, 45.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.9ms\n",
            "Speed: 0.6ms preprocess, 46.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.5ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.9ms\n",
            "Speed: 0.7ms preprocess, 43.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.6ms preprocess, 42.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.5ms preprocess, 42.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.2ms\n",
            "Speed: 0.6ms preprocess, 42.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.6ms preprocess, 42.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.3ms\n",
            "Speed: 0.6ms preprocess, 42.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.1ms\n",
            "Speed: 0.7ms preprocess, 42.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 4.1ms preprocess, 39.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.0ms\n",
            "Speed: 0.8ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.3ms\n",
            "Speed: 0.5ms preprocess, 43.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 0.6ms preprocess, 44.1ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.3ms\n",
            "Speed: 0.5ms preprocess, 44.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 1 traffic light, 42.0ms\n",
            "Speed: 0.6ms preprocess, 42.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.6ms\n",
            "Speed: 0.6ms preprocess, 41.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.6ms\n",
            "Speed: 2.6ms preprocess, 41.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.4ms\n",
            "Speed: 0.6ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.7ms\n",
            "Speed: 0.5ms preprocess, 41.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.7ms preprocess, 39.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 3.2ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.6ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 0.5ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.7ms\n",
            "Speed: 0.6ms preprocess, 45.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.9ms\n",
            "Speed: 0.5ms preprocess, 44.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.7ms\n",
            "Speed: 0.5ms preprocess, 46.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.0ms\n",
            "Speed: 0.7ms preprocess, 52.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 49.6ms\n",
            "Speed: 0.5ms preprocess, 49.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 57.8ms\n",
            "Speed: 0.6ms preprocess, 57.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.8ms\n",
            "Speed: 0.6ms preprocess, 55.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.6ms\n",
            "Speed: 0.5ms preprocess, 64.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 57.7ms\n",
            "Speed: 0.6ms preprocess, 57.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 60.1ms\n",
            "Speed: 0.5ms preprocess, 60.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 65.2ms\n",
            "Speed: 0.6ms preprocess, 65.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 61.3ms\n",
            "Speed: 0.5ms preprocess, 61.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 62.9ms\n",
            "Speed: 0.7ms preprocess, 62.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 67.4ms\n",
            "Speed: 0.5ms preprocess, 67.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.3ms\n",
            "Speed: 0.6ms preprocess, 64.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 68.6ms\n",
            "Speed: 0.6ms preprocess, 68.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 64.0ms\n",
            "Speed: 0.5ms preprocess, 64.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 62.5ms\n",
            "Speed: 0.6ms preprocess, 62.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 60.3ms\n",
            "Speed: 0.6ms preprocess, 60.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.6ms\n",
            "Speed: 0.5ms preprocess, 55.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.9ms\n",
            "Speed: 0.6ms preprocess, 55.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.8ms\n",
            "Speed: 0.5ms preprocess, 55.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.6ms\n",
            "Speed: 0.6ms preprocess, 55.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.7ms\n",
            "Speed: 0.5ms preprocess, 55.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 54.8ms\n",
            "Speed: 0.6ms preprocess, 54.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.4ms\n",
            "Speed: 0.6ms preprocess, 47.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.5ms\n",
            "Speed: 0.5ms preprocess, 47.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.6ms\n",
            "Speed: 0.6ms preprocess, 47.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 49.3ms\n",
            "Speed: 0.5ms preprocess, 49.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.3ms\n",
            "Speed: 0.6ms preprocess, 47.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.0ms\n",
            "Speed: 0.6ms preprocess, 45.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.8ms\n",
            "Speed: 0.6ms preprocess, 44.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 0.5ms preprocess, 41.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.9ms\n",
            "Speed: 0.5ms preprocess, 42.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.3ms\n",
            "Speed: 0.6ms preprocess, 41.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.2ms\n",
            "Speed: 0.7ms preprocess, 41.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.6ms\n",
            "Speed: 0.6ms preprocess, 40.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.3ms\n",
            "Speed: 0.6ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.1ms\n",
            "Speed: 0.6ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 refrigerator, 40.1ms\n",
            "Speed: 0.5ms preprocess, 40.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 0.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 0.5ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 43.3ms\n",
            "Speed: 0.5ms preprocess, 43.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.5ms\n",
            "Speed: 0.5ms preprocess, 44.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.2ms\n",
            "Speed: 0.6ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 45.5ms\n",
            "Speed: 0.6ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 46.8ms\n",
            "Speed: 0.6ms preprocess, 46.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 47.8ms\n",
            "Speed: 0.7ms preprocess, 47.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 47.5ms\n",
            "Speed: 0.6ms preprocess, 47.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 47.3ms\n",
            "Speed: 0.5ms preprocess, 47.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 48.8ms\n",
            "Speed: 0.6ms preprocess, 48.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 48.5ms\n",
            "Speed: 0.6ms preprocess, 48.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 44.1ms\n",
            "Speed: 0.6ms preprocess, 44.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 cars, 46.1ms\n",
            "Speed: 0.5ms preprocess, 46.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 cars, 44.3ms\n",
            "Speed: 0.6ms preprocess, 44.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 48.3ms\n",
            "Speed: 0.5ms preprocess, 48.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 43.2ms\n",
            "Speed: 0.6ms preprocess, 43.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 43.5ms\n",
            "Speed: 0.6ms preprocess, 43.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 42.7ms\n",
            "Speed: 0.6ms preprocess, 42.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 42.6ms\n",
            "Speed: 2.0ms preprocess, 42.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 43.1ms\n",
            "Speed: 0.7ms preprocess, 43.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 41.9ms\n",
            "Speed: 0.8ms preprocess, 41.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 42.0ms\n",
            "Speed: 3.0ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 40.6ms\n",
            "Speed: 0.5ms preprocess, 40.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 40.0ms\n",
            "Speed: 0.5ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 39.9ms\n",
            "Speed: 0.7ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XxN-ja9Pz67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "save_path = '/content/vehicle-counting-result.mp4'\n",
        "\n",
        "# Compressed video path\n",
        "compressed_path = \"/content/result_compressed.mp4\"\n",
        "\n",
        "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "O2sCsCs4M3YX"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}